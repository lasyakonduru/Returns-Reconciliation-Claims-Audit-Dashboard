# -*- coding: utf-8 -*-
"""Returns Reconciliation Automation â€“ Prototype Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17dGYrY6ZUd-aPHOjZu8R30JLzOy0GnN5

**Generating mock datasets for my project**
"""

!pip install faker

import pandas as pd
import numpy as np
from faker import Faker
import random

fake = Faker()
Faker.seed(42)
np.random.seed(42)

# Constants
NUM_RETURNS = 10000
NUM_PRODUCTS = 500
NUM_SUPPLIERS = 50

# Generate product data
product_ids = [f"P{str(i).zfill(4)}" for i in range(1, NUM_PRODUCTS + 1)]
supplier_ids = [f"S{str(i).zfill(3)}" for i in range(1, NUM_SUPPLIERS + 1)]

products = pd.DataFrame({
    "product_id": product_ids,
    "product_name": [fake.word().capitalize() for _ in range(NUM_PRODUCTS)],
    "cost_price": np.round(np.random.uniform(10, 500, NUM_PRODUCTS), 2),
    "supplier_id": np.random.choice(supplier_ids, NUM_PRODUCTS),
    "return_policy_days": np.random.randint(15, 91, NUM_PRODUCTS)
})

# Generate returns data
returns = pd.DataFrame({
    "return_id": [f"R{str(i).zfill(5)}" for i in range(1, NUM_RETURNS + 1)],
    "order_id": [f"O{str(i).zfill(5)}" for i in range(1, NUM_RETURNS + 1)],
    "product_id": np.random.choice(product_ids, NUM_RETURNS),
    "return_date": [fake.date_between(start_date='-90d', end_date='today') for _ in range(NUM_RETURNS)],
    "reason": np.random.choice(["Defective", "Wrong Item", "Changed Mind", "Damaged", "Expired"], NUM_RETURNS),
    "qty": np.random.randint(1, 10, NUM_RETURNS),
})

# Merge supplier_id into returns
returns = returns.merge(products[["product_id", "supplier_id"]], on="product_id", how="left")

# Generate claims data
claims = returns[["return_id", "product_id"]].copy()
claims["claim_id"] = ["C" + r[1:] for r in claims["return_id"]]
claims["claim_date"] = returns["return_date"] + pd.to_timedelta(np.random.randint(0, 10, NUM_RETURNS), unit='d')
claims["claim_qty"] = returns["qty"] + np.random.randint(-1, 2, NUM_RETURNS)  # may under/over claim by 1
claims["status"] = np.random.choice(["Submitted", "Approved", "Rejected"], NUM_RETURNS, p=[0.6, 0.3, 0.1])

# Save all datasets
returns_path = "/content/mock_returns.csv"
products_path = "/content/mock_products.csv"
claims_path = "/content/mock_claims.csv"

returns.to_csv(returns_path, index=False)
products.to_csv(products_path, index=False)
claims.to_csv(claims_path, index=False)

"""**Woking on the datasets**"""

# Loading the datasets
returns_df = pd.read_csv(returns_path, parse_dates=["return_date"])
products_df = pd.read_csv(products_path)
claims_df = pd.read_csv(claims_path, parse_dates=["claim_date"])

# Merging return and product policy information
merged_df = returns_df.merge(products_df, on=["product_id", "supplier_id"])

# Merging with claims data
full_df = merged_df.merge(claims_df, on=["return_id", "product_id"])

# Simulating order_date as return_date - random days within the return policy range for simplicity
full_df["order_date"] = full_df["return_date"] - pd.to_timedelta(
    np.random.randint(0, 120, size=len(full_df)), unit='d'
)

# Check 1: Is return within policy window?
full_df["days_since_order"] = (full_df["return_date"] - full_df["order_date"]).dt.days
full_df["within_policy"] = full_df["days_since_order"] <= full_df["return_policy_days"]

# Check 2: Is claimed quantity equal to returned quantity?
full_df["qty_match"] = full_df["qty"] == full_df["claim_qty"]

# Check 3: Flag records with any mismatch
full_df["reconciliation_status"] = np.where(
    full_df["within_policy"] & full_df["qty_match"], "Matched", "Mismatched"
)

# Output mismatch summary
summary = full_df["reconciliation_status"].value_counts().reset_index()
summary.columns = ["Status", "Count"]

from IPython.display import display
display(summary)

"""**Mismatch Reasons Breakdown**"""

def mismatch_reason(row):
    if row["within_policy"] and not row["qty_match"]:
        return "Qty Mismatch"
    elif not row["within_policy"] and row["qty_match"]:
        return "Late Return"
    elif not row["within_policy"] and not row["qty_match"]:
        return "Late & Qty Mismatch"
    return "No Issue"

full_df["mismatch_reason"] = full_df.apply(mismatch_reason, axis=1)

"""**Supplier Performance Metrics**"""

supplier_summary = full_df.groupby("supplier_id").agg({
    "reconciliation_status": lambda x: (x == "Matched").mean(),
    "days_since_order": "mean",
    "return_id": "count"
}).reset_index()

supplier_summary.rename(columns={
    "reconciliation_status": "Match Rate",
    "days_since_order": "Avg Days Since Order",
    "return_id": "Total Returns"
}, inplace=True)

"""**High-Risk Products**"""

product_risk = full_df.groupby("product_id").agg({
    "reconciliation_status": lambda x: (x == "Mismatched").mean(),
    "return_id": "count"
}).sort_values("reconciliation_status", ascending=False)

"""**Time Analysis**"""

full_df["return_week"] = full_df["return_date"].dt.isocalendar().week
weekly_mismatch = full_df.groupby("return_week")["reconciliation_status"].value_counts(normalize=True).unstack().fillna(0)

"""**Claim Status Validation**"""

claim_check = full_df.groupby(["reconciliation_status", "status"]).size().unstack().fillna(0)

"""**Final Dataset**"""

# Adding mismatch_reason column for better insights
def mismatch_reason(row):
    if row["within_policy"] and not row["qty_match"]:
        return "Qty Mismatch"
    elif not row["within_policy"] and row["qty_match"]:
        return "Late Return"
    elif not row["within_policy"] and not row["qty_match"]:
        return "Late & Qty Mismatch"
    return "No Issue"

full_df["mismatch_reason"] = full_df.apply(mismatch_reason, axis=1)

# Addinf return week for time-based analysis
full_df["return_week"] = full_df["return_date"].dt.isocalendar().week

# Save enriched dataset to CSV for Power BI
enriched_path = "/content/reconciliation_enriched.csv"
full_df.to_csv(enriched_path, index=False)

full_df.head(10)